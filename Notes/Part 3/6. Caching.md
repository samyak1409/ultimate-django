## What is Caching

Store results of **expensive** operations (queries, API calls) in memory so future requests are faster.

- **Benefits**:

  - Reduced response time.
  - Frees up database/web servers.
  - Helps if 3rd-party API is slow or unavailable.

- **Problems**:

  - **Stale data**: Data in DB is updated but cache still returns outdated data.
  - Need to set **expiration time** (e.g., 5 min, 3 hrs) depending on update frequency.

- **Best practices**:

  - Avoid caching if data changes frequently and must always be up-to-date.
  - Use background jobs to refresh cache when appropriate.
  - Be mindful of memory cost — aggressive caching consumes a lot of RAM.
  - Don’t cache queries that are already fast (overhead may make performance worse).

- **Rule of thumb**:

  - Always test before & after caching.
  - Don’t assume memory = always faster.
  - Remember:
    > _"Premature optimization is the root of all evil." - Donald Knuth_

## Cache Backends

- **Local Memory**: Default backend, stores cache in the same process.

  - OK for development.
  - Not suitable for production.

- **Production Backends**:

  - **Memcached** or **Redis** (both enterprise-grade).
  - Using Redis as already used as a message broker (fewer dependencies).

- **Database Backend**:

  - Can store query results in the database.
  - Faster than re-executing complex queries, but slower than memory-based cache.
  - Useful if no dedicated cache server is available.

- **File System Backend**:

  - Stores cache in files.
  - Rarely used, but available.

- **Availability**:

  - All backends except Redis are built into Django.
  - Redis requires an external package.

## Simulating a Slow API

- `pipenv install requests`

- In `playground.views`, add a new request handler.

- Use **`requests.get("https://httpbin.org/delay/2")`** to simulate a slow API.

  - `httpbin.org/delay/2` waits **2 seconds** before responding.

## Getting a Baseline Performance Benchmark

Always run a **performance test first** to establish a baseline before optimizing.

- Created a new locust file: `test_cache.py`.
- Ran the test with `100` users, `10` users/sec, until `1000` total requests.
- Result: Average (ms) = ~`3000`.
- We would compare this after adding caching.

## Installing Redis

[Already installed.](/Notes/Part%203/3.%20Running%20Background%20Tasks.md#installing-redis)

- Before configuring caching, ensure `redis` is running:

  ```sh
  docker ps
  ```

- If not, run:

  ```sh
  docker run -d -p 6379:6379 redis
  ```

## Configuring Caching

- **Install [redis cache backend](https://github.com/jazzband/django-redis)**:

  ```sh
  pipenv install django-redis
  ```

- **Cache configuration** (in `settings.py`):

  ```py
  CACHES = {
      "default": {
          "BACKEND": "django_redis.cache.RedisCache",
          "LOCATION": "redis://127.0.0.1:6379/1",  # use a DB different from Celery's redis
          "OPTIONS": {
              "CLIENT_CLASS": "django_redis.client.DefaultClient",
          },
      }
  }
  ```

  - `BACKEND`: Uses **django-redis** as cache backend.
  - `LOCATION`: Points to Redis server (`localhost:6379`).
  - Database number should be **different** from the one used by Celery's redis (avoid conflicts).
  - Redis uses numbered databases (0 to 15 by default, 16 total).

## Using the Low-level Cache API

- **Workflow**:

  - Use `cache.get(key)` to retrieve data.

  - If not found:

    - Fetch data from the actual source.
    - Store it using `cache.set(key, value)`.

  - Return cached data for subsequent requests.

  See the code in `playground.views.test_cache1()`.

- **Timeout**:

  - **Default**: 5 minutes (300s).
  - Override:
    - Per-item: `cache.set(key, value, timeout=600)`.
    - Global: In `CACHES` setting → `"TIMEOUT": 600`.

Note: Changes in code/templates doesn’t reflect until cache expires.

## Caching Views

Using low-level API in every view leads to repetitive code.  
Instead of repeating caching logic in each view, use **decorators**.

- **Function-based views (FBVs):**

  - Import: `from django.views.decorators.cache import cache_page`
  - Apply decorator: `@cache_page(timeout)`.

- **Class-based views (CBVs):**

  [Mosh has used DRF's `APIView`, but here, just use plain Django's `View`.  
   [Using class-based views](https://docs.djangoproject.com/en/5.2/topics/class-based-views/intro/#using-class-based-views)]

  - Convert FBV to CBV using `View` (`from django.views import View`).
  - Define `get(self, request)` method for logic.
  - `cache_page` cannot be applied directly to CBVs since it's a **function** decorator. Wrap with `method_decorator`.

Benefits:

- Removes need for low-level cache API.
- Django auto-generates unique cache keys.

## Verifying Optimizations

Ran with the same params as in `Getting a Baseline Performance Benchmark` section above.

But, in just under `10` secs, request count exploded to `10,000`.

Result: Average (ms) = ~`30`. (Without caching: it was ~`3000`)

## Managing Redis Cache Content

- Redis is running inside a Docker container (like a lightweight VM).

  To access Redis CLI inside the container:

  ```sh
  docker exec -it <container_id_prefix> redis-cli
  ```

  - `exec` → execute
  - `-it` → interactive mode.
  - `<container_id_prefix>` → remember: only unique prefix is needed

- Redis uses numbered databases (0 to 15 by default, 16 total).

  - To select DB 1: `select 1`

- Commands:

  - `keys *` → list all keys.
  - `del <key>` → delete a specific key. (Returns # of rows affected.)
  - `FLUSHDB` → clear **selected/current** database.
  - `FLUSHALL` → clear **all** databases in the Redis instance.
